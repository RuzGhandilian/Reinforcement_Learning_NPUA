# NPUA Reinforcement Learning Course Projects

## Overview
This repository contains a series of projects developed as part of the Reinforcement Learning (RL) course at the National Polytechnic University of Armenia (NPUA). The projects are based on the foundational concepts presented in [*Reinforcement Learning: An Introduction* by Sutton and Barto](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf). Each project focuses on implementing and analyzing key RL algorithms, with an emphasis on both theoretical understanding and practical application.

---

## Projects Overview

### Project 1: [Tic-Tac-Toe](https://github.com/RuzGhandilian/Reinforcement_Learning_NPUA/tree/master/tic-tac-toe) Game implementation
- Implementation of a Tic-Tac-Toe environment.
- Reinforcement Learning agent.
- Ability to play against the trained AI.  
ðŸ“˜ *Based on Chapter 1.5: An Extended Example: Tic-Tac-Toe*

---

### Project 2: [Multi-Armed Bandit](https://github.com/RuzGhandilian/Reinforcement_Learning_NPUA/tree/master/ten-armed-bandit) Problem
- Exploration of the exploration-exploitation trade-off in the context of the multi-armed bandit problem.
- Comparison of Optimistic Initial Values and Realistic Initial Values.
- Implementation and comparison of strategies such as Îµ-greedy algorithm, Upper Confidence Bound (UCB), and gradient bandit algorithms.  
ðŸ“˜ *Based on Chapter 2: Multi-arm Bandits*

---

###  Project 3: [Markov Decision Process](https://github.com/RuzGhandilian/Reinforcement_Learning_NPUA/tree/master/gridworld-mdp) (MDP) in Grid-World
- Implementation of **policy evaluation** and **value iteration** for a 5Ã—5 grid-world.  
- Visualization of value function convergence under random and optimal policies.  
- Demonstration of Bellman equations in finite MDPs.  
ðŸ“˜ *Based on Chapter 3: Finite Markov Decision Processes*

---

###  Project 4: [Dynamic Programming](https://github.com/RuzGhandilian/Reinforcement_Learning_NPUA/tree/master/gridworld-dp) (DP) in Grid-World  
- **Policy evaluation** and **improvement** in a 4Ã—4 grid-world with terminal states.  
- Comparison of **in-place** vs. **out-of-place** DP updates.  
- Theoretical analysis of policy improvement guarantees.  
ðŸ“˜ *Based on Chapter 4: Dynamic Programming*

---

### Project 5: [Gamblerâ€™s Problem](https://github.com/RuzGhandilian/Reinforcement_Learning_NPUA/tree/master/gambler-problem) Value Iteration Approach
- Implementation of **Value Iteration** for solving the Gambler's Problem in a finite Markov Decision Process (MDP).
- Exploration of how different stake choices maximize the probability of reaching the goal.
- Demonstration of Bellman equations in the context of the gamblerâ€™s MDP.  
ðŸ“˜ *Based on Section 4.4: Value Iteration*

---

## Each project directory contains:
- **src/**: Source code for the implementation.
- **generated_images/**: Experimental results, including plots, tables, and analysis.
- **README.md**: Detailed documentation specific to the project, including setup instructions, methodology, and key findings.
