{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 10-armed Testbed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cada6500ddd403c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:03.702582Z",
     "start_time": "2025-02-26T21:32:03.697458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Import the Bandit module\n",
    "from banditt import Bandit\n",
    "\n",
    "# Use 'Agg' backend for headless environments\n",
    "matplotlib.use('Agg')"
   ],
   "id": "1dcff3c32bd41dbd",
   "outputs": [],
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "source": [
    "def simulate(runs, times, bandits):\n",
    "    # region Summary\n",
    "    \"\"\"\n",
    "    For any learning method, we can measure its performance and behavior as it improves with experience over 1000 time steps \n",
    "    when applied to 1 of the bandit problems. This makes up 1 run. Repeating this for 2000 independent runs, each with a different \n",
    "    bandit problem, we obtained measures of the learning algorithm’s average behavior.\n",
    "    :param runs: Number of runs\n",
    "    :param times: Number of times\n",
    "    :param bandits: Bandit problems\n",
    "    :return: Optimal action count mean and reward mean\n",
    "    \"\"\"\n",
    "    # endregion Summary\n",
    "    \n",
    "    # region Body\n",
    "    \n",
    "    # Prepare a matrix filled with 0s for rewards\n",
    "    rewards = np.zeros((len(bandits),runs, times))\n",
    "    \n",
    "    # Prepare a matrix filled with 0s for optimal action counts that has the same shape as rewards matrix\n",
    "    optimal_actions = np.zeros(rewards.shape)\n",
    "\n",
    "    # For every bandit\n",
    "    for i, bandit in enumerate(bandits):\n",
    "        # for every run\n",
    "        for run in trange(runs):\n",
    "            # initialize bandit\n",
    "            bandit.initialize()\n",
    "            \n",
    "            # for every time step\n",
    "            for time in trange(times):\n",
    "            \n",
    "                # select an action\n",
    "                action = bandit.act()\n",
    "                \n",
    "                # get the reward\n",
    "                rewards[i, run, time] = bandit.step(action)\n",
    "                \n",
    "                # if the selected action is optimal for bandit\n",
    "                if action == bandit.optimal_action:\n",
    "                \n",
    "                    # change the corresponding 0 in the optimal action counts matrix to 1\n",
    "                    optimal_actions[i, run, time] = 1\n",
    "\n",
    "    return optimal_actions.mean(axis=1), rewards.mean(axis=1)\n",
    "\n",
    "    # endregion Body"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:03.711150Z",
     "start_time": "2025-02-26T21:32:03.707088Z"
    }
   },
   "id": "be09fd89ebd40d84",
   "outputs": [],
   "execution_count": 116
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Reward Distribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4088366f60e51478"
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate example reward distributions\n",
    "np.random.seed(42)\n",
    "dataset = np.random.randn(200, 10) + np.random.randn(10)\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(\"../generated_images\", exist_ok=True)\n",
    "\n",
    "# Plot and save\n",
    "plt.violinplot(dataset, showmeans=True, showmedians=True)\n",
    "plt.title(\"Figure 2.1\")\n",
    "plt.xlabel(\"Action\")\n",
    "plt.ylabel(\"Reward distribution\")\n",
    "plt.savefig(\"../generated_images/figure_2_1.png\")\n",
    "plt.close()\n",
    "\n",
    "# Print success message\n",
    "print(\"Plot saved successfully at: ../generated_images/figure_2_1.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:03.854252Z",
     "start_time": "2025-02-26T21:32:03.775513Z"
    }
   },
   "id": "8ed1daafa4064440",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved successfully at: ../generated_images/figure_2_1.png\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e8ec2e54eac562c8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Greedy Action Selection VS ε-greedy Action Selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef67eb7574c5d2b1"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of epsilons with 0, 0.1, and 0.01 values\n",
    "epsilons = [0, 0.1, 0.01]\n",
    "\n",
    "# Create a list of bandits (1 bandit for every epsilon) where every bandit uses the sample-average method\n",
    "bandits = [Bandit(epsilon=e, use_sample_averages=True) for e in epsilons]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:03.866221Z",
     "start_time": "2025-02-26T21:32:03.861884Z"
    }
   },
   "id": "6a180bc790c31e65",
   "outputs": [],
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "source": [
    "# Define number of runs\n",
    "runs = 1000\n",
    "\n",
    "# Define number of times\n",
    "times = 2000\n",
    "\n",
    "# Simulate optimal action counts and rewards\n",
    "optimal_actions_mean, rewards_mean = simulate(runs, times, bandits)\n",
    "\n",
    "print(\"Optimal Actions Mean:\", optimal_actions_mean)\n",
    "print(\"Rewards Mean:\", rewards_mean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:04.777434Z",
     "start_time": "2025-02-26T21:32:03.875900Z"
    }
   },
   "id": "683805477a8d4606",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 65560.59it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 95233.10it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 70055.69it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 62474.74it/s]\n",
      " 40%|████      | 4/10 [00:00<00:00, 33.03it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 60423.16it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 61510.43it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 63604.03it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 63386.79it/s]\n",
      " 80%|████████  | 8/10 [00:00<00:00, 30.50it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 65550.34it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 64515.84it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 30.69it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 63436.64it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 67688.82it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 105190.26it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 63418.90it/s]\n",
      " 40%|████      | 4/10 [00:00<00:00, 33.73it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 82979.94it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 75263.85it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 71178.57it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 112621.44it/s]\n",
      " 80%|████████  | 8/10 [00:00<00:00, 36.10it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 65243.93it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 68735.42it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 34.79it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 66071.28it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 68106.49it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 105007.24it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 105280.04it/s]\n",
      " 40%|████      | 4/10 [00:00<00:00, 37.12it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 67804.81it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 105257.58it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 64321.43it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 67787.83it/s]\n",
      " 80%|████████  | 8/10 [00:00<00:00, 34.94it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 68837.51it/s]\n",
      "\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 107500.78it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Actions Mean: [[0.2 0.2 0.1 ... 0.3 0.3 0.3]\n",
      " [0.1 0.2 0.1 ... 0.9 0.9 0.7]\n",
      " [0.2 0.2 0.2 ... 0.7 0.7 0.7]]\n",
      "Rewards Mean: [[-0.05324288 -0.08827834 -0.24648169 ...  0.88283043  0.68236667\n",
      "   1.18261586]\n",
      " [-0.15677273  0.06078468  0.08235715 ...  1.84344583  2.18654049\n",
      "   1.7411846 ]\n",
      " [ 0.74584366  0.54431022  1.04552864 ...  2.11290223  1.60969416\n",
      "   1.74436129]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:04.789729Z",
     "start_time": "2025-02-26T21:32:04.785654Z"
    }
   },
   "id": "e1a86ca5f4aefa2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x2000 with 0 Axes>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot average rewards over time\n",
    "plt.subplot(2, 1, 1)\n",
    "for epsilon, rewards in zip(epsilons, rewards_mean):  # Use epsilons and rewards_mean\n",
    "    plt.plot(rewards, label=fr\"$\\epsilon = {epsilon:.2f}$\")\n",
    "plt.title(\"Figure 2.2: Average Reward Over Time\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Average Reward\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:04.830059Z",
     "start_time": "2025-02-26T21:32:04.818109Z"
    }
   },
   "id": "5536109f4e591e72",
   "outputs": [],
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "source": [
    "plt.subplot(2, 1, 2)\n",
    "for epsilon, counts in zip(epsilons, optimal_actions_mean):\n",
    "    plt.plot(counts, label=fr\"$\\epsilon = {epsilon:.2f}$\")\n",
    "plt.title(\"Figure 2.3: Optimal Actions Over Time\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"% Optimal action\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:04.850679Z",
     "start_time": "2025-02-26T21:32:04.840570Z"
    }
   },
   "id": "2e6157d53f01223f",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.130863Z",
     "start_time": "2025-02-26T21:32:04.858441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.savefig(\"../generated_images/figure_2_2.png\")\n",
    "plt.close()  # Close the plot to free up memory\n",
    "\n",
    "# Print success message\n",
    "print(\"Plot saved successfully at: ../generated_images/figure_2_2.png\")"
   ],
   "id": "f31851f9d0c7be7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved successfully at: ../generated_images/figure_2_2.png\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Optimistic Initial Values VS Realistic Initial Values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0c5945f58dd0dee"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of 2 bandits where:\n",
    "# 1. 1st bandit: ε = 0, 𝑄_1(𝑎) = 5, 𝛼 = 0.1,\n",
    "# 2. 2nd bandit: ε = 0.1, 𝑄_1(𝑎) = 0, 𝛼 = 0.1\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.142492Z",
     "start_time": "2025-02-26T21:32:05.139100Z"
    }
   },
   "id": "50d647979ced258a",
   "outputs": [],
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "source": [
    "# Define number of runs\n",
    "\n",
    "\n",
    "# Define number of times\n",
    "\n",
    "\n",
    "# Simulate optimal action counts\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.159929Z",
     "start_time": "2025-02-26T21:32:05.156772Z"
    }
   },
   "id": "3116e78a4c90c435",
   "outputs": [],
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.164611Z",
     "start_time": "2025-02-26T21:32:05.162441Z"
    }
   },
   "id": "d1ae633f8632eed5",
   "outputs": [],
   "execution_count": 126
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Upper-Confidence-Bound (UCB) Action Selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7473708c239f1d0"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of 2 bandits where:\n",
    "# 1. 1st bandit: ε = 0, 𝑐 = 2, uses sample-average method,\n",
    "# 2. 2nd bandit: ε = 0.1, uses sample-average method\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.174406Z",
     "start_time": "2025-02-26T21:32:05.172109Z"
    }
   },
   "id": "1993531b4fe5feb2",
   "outputs": [],
   "execution_count": 127
  },
  {
   "cell_type": "code",
   "source": [
    "# Define number of runs\n",
    "\n",
    "\n",
    "# Define number of times\n",
    "\n",
    "\n",
    "# Simulate average rewards\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.183844Z",
     "start_time": "2025-02-26T21:32:05.181450Z"
    }
   },
   "id": "6e1fed28f6812c2e",
   "outputs": [],
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.193310Z",
     "start_time": "2025-02-26T21:32:05.190891Z"
    }
   },
   "id": "9d4db60f0153c024",
   "outputs": [],
   "execution_count": 129
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Gradient Bandit Algorithms (GBA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5cb31b7d224bbba"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of 4 bandits where:\n",
    "# 1. 1st bandit: uses GBA, 𝛼 = 0.1, uses average reward as baseline for GBA, expects true reward of 4,\n",
    "# 2. 2nd bandit: uses GBA, 𝛼 = 0.1, doesn't use average reward as baseline for GBA, expects true reward of 4,\n",
    "# 3. 3rd bandit: uses GBA, 𝛼 = 0.4, uses average reward as baseline for GBA, expects true reward of 4,\n",
    "# 4. 4th bandit: uses GBA, 𝛼 = 0.4, doesn't use average reward as baseline for GBA, expects true reward of 4\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.203211Z",
     "start_time": "2025-02-26T21:32:05.200213Z"
    }
   },
   "id": "1453e8fb0e6a32f6",
   "outputs": [],
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "source": [
    "# Define number of runs\n",
    "\n",
    "\n",
    "# Define number of times\n",
    "\n",
    "\n",
    "# Simulate optimal action counts\\\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.213889Z",
     "start_time": "2025-02-26T21:32:05.210939Z"
    }
   },
   "id": "79a2acb7e523f0a8",
   "outputs": [],
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "source": [
    "# Labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.223249Z",
     "start_time": "2025-02-26T21:32:05.221346Z"
    }
   },
   "id": "67282242fae58cb9",
   "outputs": [],
   "execution_count": 132
  },
  {
   "cell_type": "code",
   "source": [
    "# Plotting\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.233512Z",
     "start_time": "2025-02-26T21:32:05.230509Z"
    }
   },
   "id": "2281e1a4dc8f1b9c",
   "outputs": [],
   "execution_count": 133
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T21:32:05.242756Z",
     "start_time": "2025-02-26T21:32:05.240756Z"
    }
   },
   "id": "974417449ca9770c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
